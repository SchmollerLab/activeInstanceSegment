{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/florian/GitRepos/activeCell-ACDC\n",
      "ac_acdc_env\t\t\t\t\toutput\n",
      "acdc_large_cls_test_slim_coco_format.json\tpipeline_configs\n",
      "acdc_large_cls_test_slim_coco_format.json.lock\tREADME.md\n",
      "al_output\t\t\t\t\trequirements.txt\n",
      "data\t\t\t\t\t\tshell_scripts\n",
      "experiments\t\t\t\t\tsrc\n",
      "local\t\t\t\t\t\tutils\n",
      "log\t\t\t\t\t\twandb\n",
      "notebooks\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /home/florian/GitRepos/activeCell-ACDC\n",
    "!ls\n",
    "\n",
    "import json\n",
    "import random as rd\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import wandb\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "from src.globals import *\n",
    "from utils.visualization.show_image import show_image, plot_prediction\n",
    "from utils.register_datasets import register_datasets, get_dataset_name\n",
    "from utils.config_builder import get_config\n",
    "from utils.notebook_utils import *\n",
    "from utils.evaluation import SingleImageCOCOEvaluator\n",
    "from utils.evaluation_accuracy import AccuracyEvaluator\n",
    "from utils.evaluation_uncertainty import evaluate_uncertainties\n",
    "\n",
    "\n",
    "from src.test import do_test\n",
    "from src.active_learning.al_trainer import *\n",
    "from src.active_learning.mc_dropout_sampler import *\n",
    "from src.active_learning.tta_sampler import *\n",
    "\n",
    "\n",
    "logger = setup_logger(output=\"./log/main.log\",name=\"null_logger\") \n",
    "logger.addHandler(logging.NullHandler())\n",
    "logging.getLogger('detectron2').setLevel(logging.WARNING)\n",
    "logging.getLogger('detectron2').addHandler(logging.NullHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ACDC_LARGE_CLS\n",
    "test_dataset_name = dataset + \"_test_slim\"\n",
    "config_name = \"final_random_al\"\n",
    "\n",
    "model_path = \"/home/florian/GitRepos/activeCell-ACDC/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registering acdc_large_cls dataset\n",
      "registering chlamy_dataset dataset\n"
     ]
    }
   ],
   "source": [
    "register_datasets()\n",
    "train_data = DatasetCatalog.get(get_dataset_name(\n",
    "    dataset, DATASETS_DSPLITS[dataset][0]\n",
    "))\n",
    "\n",
    "test_data = DatasetCatalog.get(test_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"activeCell-ACDC\",\n",
    "    name=\"\",\n",
    "    sync_tensorboard=True,\n",
    "    mode=\"disabled\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cfg = get_config(config_name)\n",
    "cfg = default_cfg\n",
    "cfg.OUTPUT_DIR = \"./al_output/classes_acdc_large_al\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05#.4\n",
    "#cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.2\n",
    "#cfg.TEST.DETECTIONS_PER_IMAGE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(cfg, os.path.join(model_path, \"best_model.pth\"))\n",
    "#model = load_model(cfg, os.path.join(model_path, \"last_model1200.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/GitRepos/activeCell-ACDC/ac_acdc_env/lib/python3.10/site-packages/baal/bayesian/common.py:62: UserWarning: No layer was modified by patch_module!\n",
      "  warnings.warn(\"No layer was modified by patch_module!\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registering acdc_large_cls dataset\n",
      "registering chlamy_dataset dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [15:23<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 926.7615103721619 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
    "stragtegy = MCDropoutSampler(cfg)\n",
    "model = patch_module(model)\n",
    "start_time = time.time()\n",
    "res_unc = evaluate_uncertainties(cfg, test_dataset_name, model, stragtegy)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registering acdc_large_cls dataset\n",
      "registering chlamy_dataset dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/509 [00:00<?, ?it/s]/home/florian/GitRepos/activeCell-ACDC/ac_acdc_env/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  5%|▍         | 23/509 [00:55<19:42,  2.43s/it]"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
    "stragtegy = TTASampler(cfg)\n",
    "model = load_model(cfg, os.path.join(model_path, \"best_model.pth\"))\n",
    "start_time = time.time()\n",
    "res_unc = evaluate_uncertainties(cfg, test_dataset_name, model, stragtegy)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registering acdc_large_cls dataset\n",
      "registering chlamy_dataset dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/509 [00:00<?, ?it/s]/home/florian/GitRepos/activeCell-ACDC/ac_acdc_env/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 509/509 [00:42<00:00, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 46.338428020477295 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
    "cfg.AL.NUM_MC_SAMPLES = 1\n",
    "stragtegy = MCDropoutSampler(cfg)\n",
    "model = load_model(cfg, os.path.join(model_path, \"best_model.pth\"))\n",
    "start_time = time.time()\n",
    "\n",
    "# load dataset\n",
    "register_datasets()\n",
    "data_set = DatasetCatalog.get(test_dataset_name)\n",
    "for im_json in tqdm(data_set):\n",
    "    im = stragtegy.load_image(im_json)\n",
    "    stragtegy.get_samples(model, im, 1)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ac_acdc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
